# E_processador_arquivo.py - PROCESSADOR DE ARQUIVOS SERPRO LLM
"""
SISTEMA DE PROCESSAMENTO BATCH PARA AN√ÅLISE SEM√ÇNTICA DE JUSTIFICATIVAS

Este arquivo implementa um processador que:
1. L√™ um arquivo TXT com justificativas de empr√©stimos consignados
2. Envia cada justificativa para o Serpro LLM para an√°lise
3. Classifica como APROVADO, REJEITADO, REVIS√ÉO ou ERRO
4. Gera relat√≥rios detalhados e estat√≠sticas completas

ARQUITETURA:
- ProcessingResult: Dataclass que armazena resultado de cada item
- ProcessingStatistics: Dataclass que mant√©m estat√≠sticas globais
- FileProcessor: Classe principal que orquestra todo o processamento

FLUXO DE EXECU√á√ÉO:
main() ‚Üí FileProcessor.process_file() ‚Üí para cada linha: process_item() ‚Üí call_serpro_llm()
"""

import asyncio          # Para programa√ß√£o ass√≠ncrona (requisi√ß√µes HTTP simult√¢neas)
import aiohttp          # Cliente HTTP ass√≠ncrono para chamadas ao Serpro LLM
import json             # Para parsing de JSON (respostas do LLM)
import time             # Para medi√ß√£o de tempo de processamento
import sys              # Para manipula√ß√£o de paths e imports
import os               # Para vari√°veis de ambiente e sistema de arquivos
from pathlib import Path        # Para manipula√ß√£o moderna de caminhos de arquivo
from datetime import datetime  # Para timestamps e medi√ß√£o de tempo
from typing import Dict, List, Any, Optional  # Type hints para melhor documenta√ß√£o
import logging          # Para logging detalhado em arquivo
from dataclasses import dataclass, asdict    # Para estruturas de dados organizadas
import uuid             # Para gera√ß√£o de IDs √∫nicos
import traceback        # Para captura detalhada de erros

# ========== IMPORT DA CONFIGURA√á√ÉO CENTRALIZADA ==========
# Importa√ß√£o din√¢mica do arquivo 0_config.py para acesso √†s configura√ß√µes
sys.path.append(os.path.dirname(__file__))
import importlib.util
spec = importlib.util.spec_from_file_location("config", "0_config.py")
config_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(config_module)
SerproConfig = config_module.SerproConfig

# ========== ESTRUTURAS DE DADOS ==========

@dataclass
class ProcessingResult:
    """
    RESULTADO DO PROCESSAMENTO DE UM ITEM INDIVIDUAL
    
    Armazena todas as informa√ß√µes sobre o processamento de uma justificativa:
    - Dados originais (ID, CPF, pr√°tica vedada, justificativa)
    - Resultado da an√°lise LLM (diagn√≥stico, confian√ßa, justificativa)
    - Metadados (tempo, erros, tentativas)
    
    Status poss√≠veis:
    - APPROVED: Justificativa v√°lida (SIM + confian√ßa >= 0.7)
    - REVIEW_REQUIRED: Necessita revis√£o manual (SIM + 0.5 <= confian√ßa < 0.7)
    - REJECTED: Justificativa inv√°lida (N√ÉO ou confian√ßa < 0.5)
    - ERROR: Erro no processamento
    """
    id_termo: str                           # ID do termo do processo
    cpf: str                               # CPF do usu√°rio (mascarado nos logs)
    pratica_vedada: str                    # Tipo de pr√°tica vedada alegada
    justificativa: str                     # Justificativa completa do usu√°rio
    status: str                            # Status final: APPROVED/REJECTED/REVIEW_REQUIRED/ERROR
    diagnostico_llm: Optional[str] = None  # Resposta do LLM: SIM/N√ÉO
    confidence: Optional[float] = None     # N√≠vel de confian√ßa (0.0 a 1.0)
    justificativa_llm: Optional[str] = None # Explica√ß√£o do LLM sobre a decis√£o
    error_message: Optional[str] = None    # Mensagem de erro, se houver
    error_type: Optional[str] = None       # Tipo do erro para categoriza√ß√£o
    processing_time: Optional[float] = None # Tempo gasto no processamento (segundos)
    timestamp: Optional[str] = None        # Timestamp ISO 8601 do processamento
    attempt_number: int = 1                # N√∫mero da tentativa (para retry)
    
    def __post_init__(self):
        """Gera timestamp automaticamente se n√£o fornecido"""
        if self.timestamp is None:
            self.timestamp = datetime.now().isoformat()

@dataclass 
class ProcessingStatistics:
    """
    ESTAT√çSTICAS GLOBAIS DO PROCESSAMENTO
    
    Mant√©m contadores e m√©tricas sobre todo o processamento:
    - Contadores por status (aprovados, rejeitados, etc.)
    - M√©tricas de tempo e performance
    - C√°lculo autom√°tico de taxas percentuais
    """
    total_items: int = 0                   # Total de itens no arquivo
    processed: int = 0                     # Total processados at√© agora
    approved: int = 0                      # Contador de aprovados
    rejected: int = 0                      # Contador de rejeitados
    review_required: int = 0               # Contador que precisam revis√£o
    errors: int = 0                        # Contador de erros
    total_time: float = 0.0                # Tempo total gasto (segundos)
    average_time: float = 0.0              # Tempo m√©dio por item
    start_time: Optional[str] = None       # Hor√°rio de in√≠cio
    end_time: Optional[str] = None         # Hor√°rio de fim
    
    def calculate_rates(self):
        """
        CALCULA TAXAS PERCENTUAIS
        
        Retorna dicion√°rio com percentuais de cada status.
        Evita divis√£o por zero se nenhum item foi processado.
        """
        if self.processed > 0:
            return {
                "approval_rate": (self.approved / self.processed) * 100,
                "rejection_rate": (self.rejected / self.processed) * 100,
                "review_rate": (self.review_required / self.processed) * 100,
                "error_rate": (self.errors / self.processed) * 100
            }
        return {"approval_rate": 0, "rejection_rate": 0, "review_rate": 0, "error_rate": 0}

# ========== CLASSE PRINCIPAL DO PROCESSADOR ==========

class FileProcessor:
    """
    PROCESSADOR PRINCIPAL DE ARQUIVOS COM SERPRO LLM
    
    Classe que orquestra todo o processamento:
    1. Configura√ß√£o e inicializa√ß√£o
    2. Leitura e parsing do arquivo de entrada
    3. Comunica√ß√£o com Serpro LLM
    4. Gera√ß√£o de relat√≥rios e estat√≠sticas
    
    CARACTER√çSTICAS:
    - Processamento ass√≠ncrono para melhor performance
    - Sistema robusto de retry para chamadas LLM
    - Logging detalhado em arquivo
    - Valida√ß√£o de dados de entrada
    - Gera√ß√£o autom√°tica de relat√≥rios JSON
    """
    
    def __init__(self, config_file: str = None):
        """
        INICIALIZA√á√ÉO DO PROCESSADOR
        
        1. Carrega configura√ß√µes centralizadas
        2. Inicializa estruturas de dados
        3. Configura paths de entrada e sa√≠da
        4. Configura sistema de logging
        """
        # Carregar configura√ß√µes do arquivo 0_config.py
        self.config = SerproConfig()
        
        # Inicializar estruturas de controle
        self.stats = ProcessingStatistics()     # Estat√≠sticas globais
        self.results: List[ProcessingResult] = []  # Lista com todos os resultados
        
        # Configurar paths de entrada e sa√≠da (cria pastas se n√£o existirem)
        self.paths = self.config.get_file_processing_paths()
        
        # Configurar sistema de logging (apenas em arquivo, sem duplica√ß√£o)
        self.setup_logging()
        
        # Vari√°veis para comunica√ß√£o HTTP ass√≠ncrona
        self.session: Optional[aiohttp.ClientSession] = None
        
        # Controle de autentica√ß√£o com Serpro LLM
        self.access_token = None               # Token JWT atual
        self.token_expires_at = None           # Timestamp de expira√ß√£o do token
        
    def setup_logging(self):
        """
        CONFIGURA√á√ÉO DO SISTEMA DE LOGGING
        
        Configura logging APENAS para arquivo (evita duplica√ß√£o no console):
        - Log detalhado em arquivo: JSON/processamento.log
        - Formato: timestamp - level - mensagem
        - Encoding UTF-8 para caracteres especiais
        """
        log_file = self.paths["output"] / "processamento.log"
        
        # Configurar logger principal
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.INFO)
        
        # Limpar handlers existentes (evita duplica√ß√£o)
        self.logger.handlers.clear()
        
        # Configurar handler apenas para arquivo
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setFormatter(logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s'
        ))
        self.logger.addHandler(file_handler)
    
    def print_clean(self, message: str, emoji: str = ""):
        """
        SISTEMA DE OUTPUT LIMPO (SEM DUPLICA√á√ÉO)
        
        Evita duplica√ß√£o entre console e log:
        - Console: mensagem formatada com emoji
        - Arquivo: log detalhado para auditoria
        
        Args:
            message: Mensagem a ser exibida
            emoji: Emoji opcional para o console
        """
        if emoji:
            formatted_message = f"{emoji} {message}"
        else:
            formatted_message = message
        
        # Log apenas para arquivo (auditoria)
        self.logger.info(formatted_message)
        
        # Print apenas no console (experi√™ncia do usu√°rio)
        print(formatted_message)
    
    # ========== LEITURA E PARSING DE ARQUIVO ==========
    
    def read_input_file(self, filename: str = None) -> List[str]:
        """
        LEITURA DO ARQUIVO DE ENTRADA
        
        L√™ arquivo TXT com formato: IDTERMO#CPF#PRATICA VEDADA#JUSTIFICATIVA
        
        Funcionalidades:
        - Detecta automaticamente o arquivo padr√£o se n√£o especificado
        - Pula linha de cabe√ßalho se configurado
        - Remove linhas vazias
        - Preserva justificativas que contenham o caractere #
        
        Args:
            filename: Nome do arquivo (opcional, usa padr√£o se None)
            
        Returns:
            Lista de strings, cada uma representando uma linha processada
            
        Raises:
            FileNotFoundError: Se o arquivo n√£o for encontrado
        """
        # Determinar caminho do arquivo
        if filename:
            file_path = self.paths["input"] / filename
        else:
            file_path = self.paths["input_file"]  # Arquivo padr√£o (5.txt)
        
        # Verificar se arquivo existe
        if not file_path.exists():
            raise FileNotFoundError(f"Arquivo n√£o encontrado: {file_path}")
        
        self.print_clean(f"Lendo arquivo: {file_path}", "üìñ")
        
        # Ler todas as linhas com encoding UTF-8
        with open(file_path, 'r', encoding=self.config.FILE_PROCESSING["encoding"]) as f:
            lines = f.readlines()
        
        # Processar linhas (filtrar vazias, pular cabe√ßalho)
        processed_lines = []
        for i, line in enumerate(lines):
            line = line.strip()  # Remove espa√ßos e quebras de linha
            if not line:         # Pula linhas vazias
                continue
                
            # Pular linha de cabe√ßalho se configurado
            if (i == 0 and self.config.FILE_PROCESSING["skip_header"] 
                and line.startswith("IDTERMO#CPF#PRATICA VEDADA#JUSTIFICATIVA")):
                self.print_clean("Pulando linha de cabe√ßalho", "‚è≠Ô∏è")
                continue
                
            processed_lines.append(line)
        
        self.print_clean(f"Carregadas {len(processed_lines)} linhas para processamento", "‚úÖ")
        return processed_lines
    
    def parse_line(self, line: str) -> Dict[str, str]:
        """
        PARSING DE UMA LINHA DO ARQUIVO
        
        Converte string no formato: IDTERMO#CPF#PRATICA VEDADA#JUSTIFICATIVA
        Para dicion√°rio com campos nomeados.
        
        TRATAMENTO ESPECIAL:
        - Se justificativa cont√©m #, preserva o conte√∫do usando join()
        - Exemplo: "123#456#Desconto#Texto com # no meio" ‚Üí justificativa = "Texto com # no meio"
        
        Args:
            line: Linha do arquivo no formato delimitado por #
            
        Returns:
            Dicion√°rio com campos: id_termo, cpf, pratica_vedada, justificativa
            
        Raises:
            ValueError: Se formato da linha for inv√°lido (menos de 4 campos)
        """
        parts = line.split("#")
        if len(parts) < 4:
            raise ValueError(f"Formato inv√°lido. Esperado: IDTERMO#CPF#PRATICA VEDADA#JUSTIFICATIVA")
        
        return {
            "id_termo": parts[0],
            "cpf": parts[1], 
            "pratica_vedada": parts[2],
            "justificativa": "#".join(parts[3:])  # Join caso justificativa contenha #
        }
    
    def validate_data(self, data: Dict[str, str]) -> bool:
        """
        VALIDA√á√ÉO DOS DADOS DE ENTRADA
        
        Verifica se os dados atendem aos crit√©rios m√≠nimos:
        - Todos os campos obrigat√≥rios est√£o presentes
        - Justificativa tem tamanho adequado (min/max caracteres)
        - CPF v√°lido (se valida√ß√£o habilitada)
        
        Args:
            data: Dicion√°rio com dados parseados
            
        Returns:
            True se dados v√°lidos, False caso contr√°rio
        """
        validation = self.config.VALIDATION_CONFIG
        
        # Verificar campos obrigat√≥rios
        for field in validation["required_fields"]:
            if not data.get(field):
                return False
        
        # Validar tamanho da justificativa
        justificativa = data.get("justificativa", "")
        if len(justificativa) < validation["min_justificativa_length"]:
            return False
        if len(justificativa) > validation["max_justificativa_length"]:
            return False
            
        return True
    
    # ========== COMUNICA√á√ÉO COM SERPRO LLM ==========
    
    async def get_access_token(self):
        """
        OBTEN√á√ÉO DO TOKEN DE ACESSO SERPRO LLM
        
        Sistema robusto de autentica√ß√£o com:
        - Cache de token (reutiliza se ainda v√°lido)
        - Renova√ß√£o autom√°tica antes da expira√ß√£o
        - Sistema de retry com backoff exponencial
        - Tratamento espec√≠fico de erros de autentica√ß√£o
        
        FLUXO:
        1. Verifica se token atual ainda √© v√°lido
        2. Se n√£o, faz nova requisi√ß√£o OAuth2 client_credentials
        3. Armazena token e timestamp de expira√ß√£o
        4. Retry autom√°tico em caso de falha tempor√°ria
        
        Returns:
            String com access token v√°lido
            
        Raises:
            Exception: Se falhar ap√≥s todas as tentativas
        """
        # Verificar se token atual ainda √© v√°lido
        if self.access_token and self.token_expires_at:
            if datetime.now().timestamp() < self.token_expires_at:
                return self.access_token
        
        # Obter URLs e configura√ß√µes
        urls = self.config.get_urls()
        retry_config = self.config.RETRY_CONFIG
        
        # Tentar obter novo token com retry
        for attempt in range(1, retry_config["max_retries"] + 1):
            try:
                self.print_clean(f"Obtendo token (tentativa {attempt})", "üîë")
                
                # Preparar requisi√ß√£o OAuth2
                data = {"grant_type": "client_credentials"}
                auth = aiohttp.BasicAuth(self.config.CLIENT_ID, self.config.CLIENT_SECRET)
                
                # Fazer requisi√ß√£o ass√≠ncrona
                async with self.session.post(
                    urls["token"], 
                    data=data, 
                    auth=auth,
                    timeout=aiohttp.ClientTimeout(total=self.config.REQUEST_TIMEOUT)
                ) as response:
                    
                    if response.status == 200:
                        # Token obtido com sucesso
                        token_data = await response.json()
                        self.access_token = token_data["access_token"]
                        
                        # Calcular expira√ß√£o (com buffer de seguran√ßa de 5 min)
                        expires_in = token_data.get("expires_in", 3600)
                        self.token_expires_at = datetime.now().timestamp() + expires_in - 300
                        
                        self.print_clean("Token obtido com sucesso", "‚úÖ")
                        return self.access_token
                    
                    else:
                        # Erro HTTP
                        error_text = await response.text()
                        self.print_clean(f"Erro HTTP {response.status}: {error_text}", "‚ùå")
                        
                        # N√£o fazer retry para erros de autentica√ß√£o (401, 403)
                        if response.status in [401, 403]:
                            raise Exception(f"Erro de autentica√ß√£o: {response.status}")
                        
                        # Aguardar antes de retry (backoff exponencial)
                        if attempt < retry_config["max_retries"]:
                            delay = retry_config["retry_delay"] * (retry_config["backoff_multiplier"] ** (attempt - 1))
                            await asyncio.sleep(delay)
                            
            except Exception as e:
                self.print_clean(f"Erro ao obter token: {str(e)}", "üí•")
                if attempt == retry_config["max_retries"]:
                    raise
                    
                # Delay simples para outros erros
                delay = retry_config["retry_delay"] * attempt
                await asyncio.sleep(delay)
        
        raise Exception("Falha ao obter token ap√≥s todas as tentativas")
    
    async def call_serpro_llm(self, prompt: str) -> Dict[str, Any]:
        """
        CHAMADA PRINCIPAL PARA O SERPRO LLM
        
        Sistema robusto de comunica√ß√£o com:
        - Renova√ß√£o autom√°tica de token se expirado
        - Retry com backoff exponencial para falhas tempor√°rias
        - Timeouts configur√°veis
        - Tratamento espec√≠fico por tipo de erro
        
        TIPOS DE ERRO TRATADOS:
        - 401: Token expirado ‚Üí renovar e tentar novamente
        - 429: Rate limit ‚Üí aguardar mais tempo
        - 5xx: Erro servidor ‚Üí retry com backoff
        - Timeout: Problema rede ‚Üí retry
        
        Args:
            prompt: Prompt formatado para enviar ao LLM
            
        Returns:
            Dicion√°rio com resposta parseada do LLM
            
        Raises:
            Exception: Se falhar ap√≥s todas as tentativas
        """
        # Garantir que temos token v√°lido
        await self.get_access_token()
        
        # Preparar requisi√ß√£o
        urls = self.config.get_urls()
        retry_config = self.config.RETRY_CONFIG
        
        headers = {
            "Authorization": f"Bearer {self.access_token}",
            "Content-Type": "application/json"
        }
        
        # Payload no formato esperado pelo Serpro LLM (compat√≠vel OpenAI)
        payload = {
            "model": self.config.MODEL_NAME,
            "messages": [{"role": "user", "content": prompt}],
            **self.config.LLM_CONFIG  # temperature, max_tokens, etc.
        }
        
        # Tentativas com retry
        for attempt in range(1, retry_config["max_retries"] + 1):
            try:
                async with self.session.post(
                    f"{urls['api']}/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=self.config.REQUEST_TIMEOUT)
                ) as response:
                    
                    if response.status == 200:
                        # Sucesso - parsear resposta
                        result = await response.json()
                        return self.parse_llm_response(result)
                    
                    elif response.status == 401:
                        # Token expirado - renovar e continuar loop
                        self.print_clean("Token expirado, renovando...", "üîÑ")
                        self.access_token = None
                        await self.get_access_token()
                        continue
                    
                    else:
                        # Outros erros HTTP
                        error_text = await response.text()
                        raise Exception(f"HTTP {response.status}: {error_text}")
                        
            except asyncio.TimeoutError:
                # Timeout - tentar novamente
                self.print_clean(f"Timeout na tentativa {attempt}", "‚è∞")
                if attempt == retry_config["max_retries"]:
                    raise Exception("Timeout na chamada LLM")
                    
            except Exception as e:
                # Outros erros
                self.print_clean(f"Erro LLM tentativa {attempt}: {str(e)}", "‚ùå")
                if attempt == retry_config["max_retries"]:
                    raise
                    
            # Aguardar antes de pr√≥xima tentativa (backoff exponencial)
            delay = retry_config["retry_delay"] * (retry_config["backoff_multiplier"] ** (attempt - 1))
            await asyncio.sleep(delay)
        
        raise Exception("Falha na chamada LLM ap√≥s todas as tentativas")
    
    def parse_llm_response(self, response: Dict) -> Dict[str, Any]:
        """
        PARSING DA RESPOSTA DO LLM
        
        Converte resposta bruta do LLM em formato estruturado.
        Tenta m√∫ltiplas estrat√©gias para extrair JSON:
        
        1. JSON direto (resposta j√° √© JSON v√°lido)
        2. Extra√ß√£o via regex (JSON embutido em texto)
        3. Fallback inteligente (an√°lise por palavras-chave)
        
        Args:
            response: Resposta bruta do Serpro LLM
            
        Returns:
            Dicion√°rio com campo "llm_analysis" contendo dados estruturados
            
        Raises:
            Exception: Se formato da resposta for completamente inv√°lido
        """
        try:
            # Extrair conte√∫do da resposta
            content = response["choices"][0]["message"]["content"]
            
            # Estrat√©gia 1: JSON direto
            try:
                if content.strip().startswith('{'):
                    return {"llm_analysis": json.loads(content)}
                
                # Estrat√©gia 2: Extra√ß√£o via regex
                import re
                json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content, re.DOTALL)
                if json_match:
                    return {"llm_analysis": json.loads(json_match.group())}
                
            except json.JSONDecodeError:
                pass
            
            # Estrat√©gia 3: Fallback inteligente
            return {"llm_analysis": self.create_fallback_response(content)}
            
        except (KeyError, IndexError) as e:
            raise Exception(f"Formato de resposta LLM inv√°lido: {e}")
    
    def create_fallback_response(self, content: str) -> Dict[str, Any]:
        """
        FALLBACK INTELIGENTE PARA RESPOSTAS N√ÉO-JSON
        
        Quando o LLM n√£o retorna JSON v√°lido, analisa o texto por palavras-chave
        para determinar se a justificativa deve ser aprovada ou rejeitada.
        
        ALGORITMO:
        1. Converte texto para min√∫sculas
        2. Conta palavras que indicam aprova√ß√£o vs rejei√ß√£o
        3. Determina diagn√≥stico baseado na contagem
        4. Calcula confian√ßa baseada na for√ßa das indica√ß√µes
        
        Args:
            content: Texto bruto da resposta do LLM
            
        Returns:
            Dicion√°rio no formato esperado com diagn√≥stico inferido
        """
        content_lower = content.lower()
        
        # Palavras que indicam que a justificativa deve ser aprovada
        approve_words = ["sim", "aprovado", "v√°lido", "procedente", "autoriza√ß√£o", "liquidado", "cr√©dito"]
        
        # Palavras que indicam que a justificativa deve ser rejeitada
        reject_words = ["n√£o", "rejeitado", "inv√°lido", "taxa", "boleto", "renegociar"]
        
        # Contar ocorr√™ncias
        approve_count = sum(1 for word in approve_words if word in content_lower)
        reject_count = sum(1 for word in reject_words if word in content_lower)
        
        # Determinar diagn√≥stico baseado na contagem
        if approve_count > reject_count:
            diagnostico = "SIM"
            confidence = min(0.9, 0.5 + (approve_count * 0.1))
        else:
            diagnostico = "N√ÉO"
            confidence = min(0.9, 0.5 + (reject_count * 0.1))
        
        # Retornar no formato padr√£o
        return {
            "requestId": str(uuid.uuid4()),
            "timestamp": datetime.now().strftime("%Y-%m-%dT%H:%M:%S-03:00"),
            "diagnosticoLLM": diagnostico,
            "justificativaLLM": content[:144],  # Limitar a 144 caracteres
            "confidence": confidence,
            "status": "success"
        }
    
    # ========== PROCESSAMENTO PRINCIPAL ==========
    
    async def process_item(self, line: str, item_number: int) -> ProcessingResult:
        """
        PROCESSAMENTO DE UM ITEM INDIVIDUAL
        
        Fluxo completo para processar uma justificativa:
        1. Parse da linha do arquivo
        2. Valida√ß√£o dos dados
        3. Cria√ß√£o do prompt para o LLM
        4. Chamada ao Serpro LLM
        5. An√°lise da resposta e determina√ß√£o do status final
        6. Cria√ß√£o do resultado estruturado
        
        L√ìGICA DE CLASSIFICA√á√ÉO:
        - APPROVED: SIM + confian√ßa >= 0.7
        - REVIEW_REQUIRED: SIM + 0.5 <= confian√ßa < 0.7
        - REJECTED: N√ÉO ou confian√ßa < 0.5
        - ERROR: Erro em qualquer etapa
        
        Args:
            line: Linha do arquivo no formato delimitado
            item_number: N√∫mero sequencial do item (para identifica√ß√£o)
            
        Returns:
            ProcessingResult com todos os dados e resultado da an√°lise
        """
        start_time = time.time()
        
        try:
            # 1. Parse da linha
            data = self.parse_line(line)
            
            # 2. Valida√ß√£o dos dados
            if not self.validate_data(data):
                return ProcessingResult(
                    **data,
                    status="ERROR",
                    error_message="Dados inv√°lidos",
                    error_type="VALIDATION_ERROR",
                    processing_time=time.time() - start_time
                )
            
            # 3. Criar prompt usando template configurado
            prompt = self.config.get_prompt_template().format(justificativa=data["justificativa"])
            
            # 4. Chamar Serpro LLM
            llm_response = await self.call_serpro_llm(prompt)
            llm_result = llm_response.get("llm_analysis", {})
            
            # 5. Extrair resultados da an√°lise
            diagnostico_llm = llm_result.get("diagnosticoLLM", "N√ÉO")
            confidence = llm_result.get("confidence", 0.5)
            justificativa_llm = llm_result.get("justificativaLLM", "")
            
            # 6. Determinar status final baseado na l√≥gica de neg√≥cio
            if diagnostico_llm == "SIM" and confidence >= 0.7:
                status = "APPROVED"           # Alta confian√ßa - aprovar
            elif diagnostico_llm == "SIM" and confidence >= 0.5:
                status = "REVIEW_REQUIRED"    # M√©dia confian√ßa - revisar
            else:
                status = "REJECTED"           # Baixa confian√ßa ou N√ÉO - rejeitar
            
            # 7. Criar resultado estruturado
            result = ProcessingResult(
                **data,
                status=status,
                diagnostico_llm=diagnostico_llm,
                confidence=confidence,
                justificativa_llm=justificativa_llm,
                processing_time=time.time() - start_time
            )
            
            # 8. Salvar resultado individual se configurado
            if self.config.FILE_PROCESSING["save_individual_files"]:
                await self.save_individual_result(result)
            
            return result
            
        except Exception as e:
            # Tratamento de erros - criar resultado de erro
            self.print_clean(f"Erro no item {item_number}: {str(e)}", "üí•")
            
            # Tentar parsear dados para o resultado de erro
            try:
                data = self.parse_line(line)
            except:
                # Se parse falhar, criar dados m√≠nimos
                data = {"id_termo": f"ERRO_{item_number}", "cpf": "", "pratica_vedada": "", "justificativa": line}
            
            return ProcessingResult(
                **data,
                status="ERROR",
                error_message=str(e),
                error_type=type(e).__name__,
                processing_time=time.time() - start_time
            )
    
    # ========== PERSIST√äNCIA E RELAT√ìRIOS ==========
    
    async def save_individual_result(self, result: ProcessingResult):
        """
        SALVAR RESULTADO INDIVIDUAL EM ARQUIVO JSON
        
        Cria um arquivo JSON para cada item processado, permitindo:
        - Auditoria detalhada de cada decis√£o
        - Reprocessamento individual se necess√°rio
        - An√°lise posterior dos resultados
        
        Formato do arquivo: {id_termo}.json
        Localiza√ß√£o: pasta JSON/ configurada
        
        Args:
            result: Resultado a ser salvo
        """
        filename = f"{result.id_termo}.json"
        filepath = self.paths["output"] / filename
        
        # Salvar com formata√ß√£o leg√≠vel e encoding UTF-8
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(asdict(result), f, indent=self.config.JSON_CONFIG["indent"], ensure_ascii=False)
    
    def update_statistics(self, result: ProcessingResult):
        """
        ATUALIZAR ESTAT√çSTICAS GLOBAIS
        
        Incrementa contadores baseado no resultado:
        - Contadores por status (approved, rejected, etc.)
        - M√©tricas de tempo (total e m√©dio)
        - Total processado
        
        Args:
            result: Resultado para contabilizar
        """
        self.stats.processed += 1
        
        # Incrementar contador espec√≠fico
        if result.status == "APPROVED":
            self.stats.approved += 1
        elif result.status == "REJECTED":
            self.stats.rejected += 1
        elif result.status == "REVIEW_REQUIRED":
            self.stats.review_required += 1
        elif result.status == "ERROR":
            self.stats.errors += 1
        
        # Atualizar m√©tricas de tempo
        if result.processing_time:
            self.stats.total_time += result.processing_time
            self.stats.average_time = self.stats.total_time / self.stats.processed
    
    # ========== INTERFACE DO USU√ÅRIO ==========
    
    def print_progress(self, current: int, total: int, result: ProcessingResult):
        """
        EXIBIR PROGRESSO DETALHADO DO PROCESSAMENTO
        
        Mostra informa√ß√µes completas sobre cada item processado:
        - Identifica√ß√£o e progresso ([1/5] 20.0%)
        - Status final com emoji visual
        - Justificativa completa do usu√°rio
        - Diagn√≥stico e confian√ßa do LLM
        - Justificativa/raz√£o do LLM
        - M√©tricas de tempo e erros
        
        FORMATO VISUAL:
        ----------------------------------------------------------------------
        [1/5] (20.0%) ‚úÖ TERMO123 - APPROVED
        ----------------------------------------------------------------------
        üë§ USU√ÅRIO: Justificativa completa aqui...
        ü§ñ LLM: SIM (confian√ßa: 0.85) üéØ
        üí≠ RAZ√ÉO: Justificativa v√°lida - desconto sem autoriza√ß√£o
        ‚ÑπÔ∏è  INFO: ‚è±Ô∏è 14.2s
        ‚è≥ Aguardando 1.0s para pr√≥ximo item...
        ----------------------------------------------------------------------
        
        Args:
            current: N√∫mero do item atual
            total: Total de itens
            result: Resultado do processamento
        """
        
        # Mapeamento de status para emojis visuais
        status_emojis = {
            "APPROVED": "‚úÖ",        # Aprovado
            "REJECTED": "‚ùå",        # Rejeitado
            "REVIEW_REQUIRED": "‚ö†Ô∏è", # Precisa revis√£o
            "ERROR": "üí•"            # Erro
        }
        
        emoji = status_emojis.get(result.status, "‚ùì")
        percentage = (current / total) * 100
        
        # Cabe√ßalho com progresso
        print(f"\n{'-'*70}")
        print(f"[{current}/{total}] ({percentage:.1f}%) {emoji} {result.id_termo} - {result.status}")
        print(f"{'-'*70}")
        
        # Justificativa do usu√°rio COMPLETA (sem cortes)
        print(f"üë§ USU√ÅRIO: {result.justificativa}")
        
        # Resultado da an√°lise LLM
        if result.diagnostico_llm:
            # Indicador visual de confian√ßa
            confidence_indicator = "üéØ" if result.confidence and result.confidence >= 0.7 else "ü§î"
            confidence_text = f" (confian√ßa: {result.confidence:.2f})" if result.confidence else ""
            print(f"ü§ñ LLM: {result.diagnostico_llm}{confidence_text} {confidence_indicator}")
        
        # Justificativa/raz√£o do LLM
        if result.justificativa_llm:
            print(f"üí≠ RAZ√ÉO: {result.justificativa_llm}")
        
        # Informa√ß√µes adicionais (tempo, erros)
        info_parts = []
        if result.processing_time:
            info_parts.append(f"‚è±Ô∏è {result.processing_time:.1f}s")
        if result.error_message:
            info_parts.append(f"üí• {result.error_message}")
        
        if info_parts:
            print(f"‚ÑπÔ∏è  INFO: {' | '.join(info_parts)}")
        
        # Indicador de pausa (exceto √∫ltimo item)
        if current < total:
            delay = self.config.FILE_PROCESSING["delay_between_requests"]
            print(f"‚è≥ Aguardando {delay}s para pr√≥ximo item...")
        
        print(f"{'-'*70}")
    
    async def save_final_statistics(self):
        """
        SALVAR ESTAT√çSTICAS FINAIS EM ARQUIVO JSON
        
        Gera relat√≥rio completo com:
        - Estat√≠sticas de processamento
        - Taxas percentuais
        - Configura√ß√µes utilizadas
        - Lista detalhada de todos os resultados
        
        Arquivo gerado: JSON/estatisticas.json
        """
        if not self.config.STATS_CONFIG["save_stats"]:
            return
        
        rates = self.stats.calculate_rates()
        
        # Estrutura completa do relat√≥rio
        final_stats = {
            "processamento": asdict(self.stats),
            "taxas": rates,
            "configuracao": {
                "modelo_llm": self.config.MODEL_NAME,
                "arquivo_processado": str(self.paths["input_file"]),
                "pasta_output": str(self.paths["output"])
            },
            "resultados_detalhados": [asdict(r) for r in self.results]
        }
        
        # Salvar com formata√ß√£o leg√≠vel
        stats_file = self.paths["stats_file"]
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(final_stats, f, indent=2, ensure_ascii=False)
        
        self.print_clean(f"Estat√≠sticas salvas em: {stats_file}", "üíæ")
    
    def print_final_summary(self):
        """
        EXIBIR RELAT√ìRIO FINAL COMPLETO
        
        Sum√°rio detalhado do processamento com:
        - Informa√ß√µes do arquivo e configura√ß√£o
        - M√©tricas de performance
        - Resultados por categoria
        - An√°lise de proced√™ncia
        - Arquivos gerados
        - Per√≠odo de execu√ß√£o
        
        FORMATO:
        ======================================================================
        üìä RELAT√ìRIO FINAL - SERPRO LLM
        ======================================================================
        üìÅ Arquivo processado: 5.txt
        ü§ñ Modelo utilizado: deepseek-r1-distill-qwen-14b
        [... mais informa√ß√µes ...]
        ======================================================================
        """
        rates = self.stats.calculate_rates()
        
        print(f"\n{'='*70}")
        print("üìä RELAT√ìRIO FINAL - SERPRO LLM")
        print(f"{'='*70}")
        
        # Informa√ß√µes b√°sicas do processamento
        print(f"üìÅ Arquivo processado: {self.paths['input_file'].name}")
        print(f"ü§ñ Modelo utilizado: {self.config.MODEL_NAME}")
        print(f"üåê Ambiente: {self.config.AMBIENTE}")
        print(f"üìà Total processado: {self.stats.processed} itens")
        
        # M√©tricas de performance
        print(f"\n‚è±Ô∏è PERFORMANCE:")
        print(f"   Tempo total: {self.stats.total_time:.1f}s ({self.stats.total_time/60:.1f} min)")
        print(f"   Tempo m√©dio por item: {self.stats.average_time:.1f}s")
        
        # Resultados detalhados por categoria
        print(f"\nüéØ RESULTADOS DETALHADOS:")
        print(f"   ‚úÖ Aprovados: {self.stats.approved} ({rates['approval_rate']:.1f}%)")
        print(f"   ‚ö†Ô∏è Necessitam revis√£o: {self.stats.review_required} ({rates['review_rate']:.1f}%)")
        print(f"   ‚ùå Rejeitados: {self.stats.rejected} ({rates['rejection_rate']:.1f}%)")
        print(f"   üí• Erros: {self.stats.errors} ({rates['error_rate']:.1f}%)")
        
        # An√°lise de proced√™ncia (aprovados + revis√£o = casos v√°lidos)
        print(f"\nüìã AN√ÅLISE:")
        total_validos = self.stats.approved + self.stats.review_required
        if total_validos > 0:
            taxa_procedencia = (total_validos / self.stats.processed) * 100
            print(f"   üìà Taxa de proced√™ncia: {taxa_procedencia:.1f}% ({total_validos} de {self.stats.processed})")
        
        # Status de qualidade do processamento
        if self.stats.errors == 0:
            print(f"   üéâ Processamento sem erros!")
        else:
            print(f"   ‚ö†Ô∏è {self.stats.errors} erros encontrados - verifique os logs")
        
        # Arquivos gerados para auditoria
        print(f"\nüíæ ARQUIVOS GERADOS:")
        print(f"   üìä Estat√≠sticas: {self.paths['stats_file']}")
        print(f"   üìÅ JSONs individuais: {self.paths['output']}")
        print(f"   üìù Log detalhado: {self.paths['output']}/processamento.log")
        
        # Per√≠odo de execu√ß√£o
        if self.stats.start_time and self.stats.end_time:
            inicio = datetime.fromisoformat(self.stats.start_time).strftime("%H:%M:%S")
            fim = datetime.fromisoformat(self.stats.end_time).strftime("%H:%M:%S")
            print(f"\nüïê PER√çODO: {inicio} ‚Üí {fim}")
        
        print(f"{'='*70}")
        print("üéâ PROCESSAMENTO CONCLU√çDO COM SUCESSO!")
        print(f"{'='*70}")
    
    # ========== M√âTODO PRINCIPAL ==========
    
    async def process_file(self, filename: str = None):
        """
        M√âTODO PRINCIPAL - PROCESSAR ARQUIVO COMPLETO
        
        Orquestra todo o fluxo de processamento:
        1. Inicializa√ß√£o da sess√£o HTTP
        2. Leitura do arquivo de entrada
        3. Loop de processamento item por item
        4. Gera√ß√£o de relat√≥rios finais
        5. Cleanup de recursos
        
        CONTROLE DE FLUXO:
        - Processamento sequencial com delay configur√°vel
        - Tratamento robusto de erros
        - Logging detalhado
        - Cleanup garantido em finally
        
        Args:
            filename: Nome do arquivo (opcional, usa padr√£o se None)
            
        Raises:
            Exception: Erros fatais s√£o propagados ap√≥s logging
        """
        try:
            # 1. Inicializar sess√£o HTTP ass√≠ncrona
            self.session = aiohttp.ClientSession()
            
            # 2. Ler e preparar dados do arquivo
            lines = self.read_input_file(filename)
            self.stats.total_items = len(lines)
            self.stats.start_time = datetime.now().isoformat()
            
            self.print_clean(f"Iniciando processamento de {len(lines)} itens", "üöÄ")
            
            # 3. Loop principal - processar cada linha
            for i, line in enumerate(lines, 1):
                # Processar item individual
                result = await self.process_item(line, i)
                
                # Armazenar resultado e atualizar estat√≠sticas
                self.results.append(result)
                self.update_statistics(result)
                
                # Exibir progresso detalhado
                self.print_progress(i, len(lines), result)
                
                # Delay entre requests (evita sobrecarga do servidor)
                if i < len(lines):
                    await asyncio.sleep(self.config.FILE_PROCESSING["delay_between_requests"])
            
            # 4. Finaliza√ß√£o e relat√≥rios
            self.stats.end_time = datetime.now().isoformat()
            
            # Salvar estat√≠sticas em arquivo JSON
            await self.save_final_statistics()
            
            # Exibir relat√≥rio final no console
            self.print_final_summary()
            
        except Exception as e:
            # Tratamento de erros fatais
            self.print_clean(f"Erro fatal: {str(e)}", "üí•")
            self.logger.error(traceback.format_exc())
            raise
            
        finally:
            # Cleanup garantido (fechar sess√£o HTTP)
            if self.session:
                await self.session.close()

# ========== FUN√á√ÉO PRINCIPAL DE EXECU√á√ÉO ==========

async def main():
    """
    FUN√á√ÉO PRINCIPAL DO PROGRAMA
    
    Ponto de entrada que:
    1. Exibe cabe√ßalho do programa
    2. Carrega e valida configura√ß√µes
    3. Verifica exist√™ncia do arquivo de entrada
    4. Executa o processamento
    5. Trata interrup√ß√µes e erros
    
    TRATAMENTO DE CASOS:
    - Arquivo n√£o encontrado ‚Üí cria exemplo automaticamente
    - Ctrl+C ‚Üí interrup√ß√£o graceful
    - Erros ‚Üí logging e exit code apropriado
    
    Returns:
        0 se sucesso, 1 se erro
    """
    print("ü§ñ PROCESSADOR DE ARQUIVO - SERPRO LLM")
    print("="*50)
    
    # Carregar configura√ß√µes
    config = SerproConfig()
    
    # Criar inst√¢ncia do processador
    processor = FileProcessor()
    
    # Verificar se arquivo de entrada existe
    if not processor.paths["input_file"].exists():
        print(f"‚ùå Arquivo n√£o encontrado: {processor.paths['input_file']}")
        print("üí° Criando arquivo de exemplo...")
        config.create_sample_input_file()
        print(f"üìÅ Use o arquivo criado ou coloque seu arquivo em: {processor.paths['input']}")
        return
    
    try:
        # Executar processamento principal
        await processor.process_file()
        
    except KeyboardInterrupt:
        # Interrup√ß√£o pelo usu√°rio (Ctrl+C)
        print("\n‚èπÔ∏è Processamento interrompido pelo usu√°rio")
        
    except Exception as e:
        # Outros erros
        print(f"\nüí• Erro: {str(e)}")
        return 1
    
    return 0

# ========== PONTO DE ENTRADA ==========

if __name__ == "__main__":
    """
    EXECU√á√ÉO PRINCIPAL
    
    Executa a fun√ß√£o main() de forma ass√≠ncrona e retorna exit code apropriado.
    O asyncio.run() gerencia automaticamente o event loop.
    """
    exit_code = asyncio.run(main())